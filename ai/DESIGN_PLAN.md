# SOP AI: Design Plan for Robust Expert System Infrastructure

**Date:** December 3, 2025
**Status:** Draft / In-Design

## 1. Executive Summary

The goal of `sop-ai` is to provide a **"Smart, Transactional, Embedded Knowledge Store"** that serves as the foundational infrastructure for building robust Expert Systems and Automation tools.

Unlike typical RAG (Retrieval-Augmented Generation) systems that treat data as unstructured text blobs, `sop-ai` aims to bring **Database Discipline** to AI. It combines the flexibility of Vector Search with the reliability of B-Tree transactions and the intelligence of LLM-driven curation.

This infrastructure is designed not just for "Chat with PDF" use cases, but for building complex automation systems (e.g., RESTful API generators, Payroll managers, Medical Expert Systems) where data structure and integrity are paramount.

## 2. The Core Problem: "Garbage In, Garbage Out"

Current industry standard RAG pipelines often suffer from:
1.  **Lack of Structure**: Data is chunked and dumped into vector stores without rigorous schema enforcement.
2.  **No Transactional Integrity**: Most vector stores are eventually consistent or lack ACID properties, making them unsuitable for critical business data (e.g., payroll).
3.  **Poor Data Hygiene**: "Dirty" or irrelevant data clogs the index, leading to hallucinations.
4.  **Dependency Hell**: Requires a complex stack (Python + Postgres + Pinecone + Redis + LangChain).

## 3. The Solution: The "Curator" Pipeline

We propose a formal **Knowledge Engineering Phase** integrated directly into the database engine.

### 3.1. The Ingestion Flow
Instead of raw ingestion, data flows through a "Curator" (an LLM or specialized Agent) before storage.

1.  **Raw Input**: Unstructured or semi-structured data (e.g., "Patient has fever", "GET /users returns list").
2.  **The Curator**:
    *   **Validates**: Checks if data fits the domain.
    *   **Categorizes**: Assigns a strict taxonomy (e.g., `Category: Respiratory`, `Category: API_Endpoint`).
    *   **Structures**: Extracts entities into a defined Schema (JSON Payload).
    *   **Synthesizes**: Rewrites content for optimal retrieval.
3.  **The Vector Store (Semantic Routing)**:
    *   Data is routed to specific **Centroids** based on the Curator's categorization.
    *   This physically organizes the B-Tree index by topic, improving search speed and relevance.

### 3.2. Local Intelligence
To ensure scalability and privacy, the Curator is designed to run **Locally** (e.g., via Ollama/Llama3 or specialized internal models). This turns the "Intelligence Cost" into a one-time build-time cost, rather than a recurring runtime cost.

## 4. Data Modeling: Beyond Text

To support diverse applications (REST APIs, Payroll, etc.), `sop-ai` must move beyond hardcoded `text` and `description` fields.

### 4.1. Generic Payload Support
The system will support a generic `Payload` field (JSON/Map) that stores the structured data.

```go
type DataItem struct {
    ID       string
    Vector   []float32
    // The "Searchable" representation (generated by Curator)
    Text     string 
    // The "Structured" data (defined by User Schema)
    Payload  map[string]any 
    // Metadata for routing
    Category string 
}
```

### 4.2. User-Defined Schemas
Users should be able to define the "Shape" of their data.
*   **Doctor Agent**: `Payload { "symptoms": [], "treatment": "..." }`
*   **API Agent**: `Payload { "endpoint": "/users", "method": "GET", "params": [...] }`

*Future Goal*: Implement a schema validation layer (like JSON Schema) that the Curator enforces.

## 5. Industry Landscape & The "SOP Edge"

| Feature | Standard Vector DBs (Pinecone/Milvus) | Orchestrators (LangChain) | **SOP AI** |
| :--- | :--- | :--- | :--- |
| **Deployment** | Server / Cloud Service | Library (Python/JS) | **Embedded Go Binary** |
| **Transactions** | Eventual Consistency | N/A | **ACID (B-Tree)** |
| **Data Cleaning** | External Process | Pipeline Step | **Integrated "Curator"** |
| **Storage** | Vectors + Metadata | N/A | **Vectors + Structured Data** |
| **Cost** | High (Cloud/Ops) | N/A | **Low (Local/Embedded)** |

**Our Edge**: We provide the **Infrastructure SDK** that allows a developer to build a "Local Curator" and a "Transactional Knowledge Store" in a single package. This enables "IT Shops" to build bespoke AI solutions (like a Payroll Manager) that run entirely on-premise with high reliability.

## 6. Implementation Roadmap

### Phase 1: Foundation (Current)
- [x] Hybrid Search (Vector + BM25).
- [x] B-Tree Persistence.
- [x] Basic Agent/Pipeline Architecture.

### Phase 2: The Curator (Next Steps)
- [ ] **Configurable ETL**: Add `ETLConfig` to define Curator steps.
- [ ] **Ollama Integration**: Allow the ingestion pipeline to call local LLMs for data transformation.
- [ ] **Generic Payloads**: Update `DataItem` and `VectorStore` to handle `map[string]any` payloads.

### Phase 3: Semantic Routing
- [ ] **Category-Driven Centroids**: Use the Curator's output (`Category`) to force vector clustering.
- [ ] **Weighted Search**: Allow biasing search results based on Text vs. Vector matches.

### Phase 4: Schema Enforcement (Future)
- [ ] **Schema Definition**: Allow users to define expected JSON structure.
- [ ] **Validator Agent**: A specialized agent that rejects data violating the schema.

## 7. Use Case Example: RESTful API Builder

**Goal**: An IT shop wants to build a system that acts as a RESTful API for Payroll, managed by AI.

1.  **Setup**: Define Schema `{ "employee_id": "int", "salary": "float" }`.
2.  **Ingestion**:
    *   Input: "John Doe earns 50k".
    *   **Curator**: Extracts `{ "employee_id": 101, "salary": 50000 }`.
    *   **Store**: Saves structured record in `sop` B-Tree (ACID compliant).
3.  **Runtime**:
    *   User: "Give John a raise to 55k".
    *   **Agent**: Retrieves record, updates Payload, commits Transaction.
## 8. Architecture & Packaging

### 8.1. Modular Separation
To prevent "bloat" for users who only need the core B-Tree database (`sop`), we will separate the AI components into their own module.

*   **`github.com/sharedcode/sop`**: The core database engine (B-Trees, Transactions, Backends). Lightweight and focused on storage.
*   **`github.com/sharedcode/sop/ai`**: The AI layer (Vector Store, Agents, Curator). This module will depend on `sop` but will carry the heavier dependencies required for LLM integration (e.g., HTTP clients, potential future bindings).

**Action Item**: Create `ai/go.mod` to formalize this separation. This ensures that a developer building a simple Key-Value store doesn't pull in the entire AI stack.

