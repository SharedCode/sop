Welcome to SOP!

This is a port from c#, thus, our coding style is very modular because the goal here is to also expand to support
an Enterprise layout. Meaning, create B-Tree constructs that can optionally use out of process Caching(e.g. Redis)
& a backend Store like Cassandra or AWS S3.

On Persistence
* Will use go generics for type system. The c# implementation uses a very rich type system. Public interfaces
  standardizes on "generics" and internal SOP constructs use a custom serializer for efficient data storage.
  In golang port, standardizing on generics in both internal & external constructs will simplify the Key/Value
  type support and resulting serialization can standardize on go's object Marshalling functions.
  go's marshaller(json &/or protobuff) has decent object serialization, thus, no need to get overboard.
* Will standardize on protocol buffers for performant node (including "item" or "key/value") serialization, like in the c# version,
  items are serialized to a target linked list of DataBlocks, which, in turn is what is stored in the storage system.
  NOTE: json supports streaming, protobuff seems not, so, json wins: https://stackoverflow.com/questions/31794355/decode-large-stream-json
* Caching, we will cache the DataBlocks which is keyed off of its Id (e.g. - UUID). DataBlock(s) contain the
  serialized data of a B-Tree Node or a large object(Value).

On Transactions
* Use Redis/C* for storing Transaction changes
* Early conflict resolution, If current item being "managed" is already modified by another transaction, trigger a rollback

On Persistence & Transaction(V2)
Scenario: transaction for writing
* Node(s) when initially created or when modified only resides in the host server's memory
  - Node(s) & their "items" w/ version # are cached
* During Commit, transaction will...
  - use Redis/C* for conflict detection, rollback if needed
    if any of the "item" is already modified(version # changed) by another transaction, rollback
  - (Phase 1) if there is no conflict & transaction survived
    upsert to Cassandra registry(target are non-active physical UUIDs so reader clients will not pick up the changes!)
      to reflect the "in-flight" items' changes, sync up Redis
    persist new/modified nodes to the backend store
  - (Phase 2) when everything is successfully persisted,
    update C*/Redis to switch the non-active UUIDs as the active UUIDs & increase the "item(s)" & node(s) version #s by 1
  - Rollback (or undo changes in the) transaction if any of the operation failed, from phase 1 to 2
Scenario: transaction for reading
* When fetching, check the Item if already fetched from this transaction and if it is & version is different 
  then fail the (fetch/) transaction.
  Each Item "fetched" from B-Tree will track the item's version # (cache the item in memory)
* On transaction Commit(completion)...
  - check if there was any "fetch" error of type transaction
    fail commit if there is
  - check each of Item(s) version #(compare with Redis'/C*' copy) if not modified, if any were modified fail commit
  - if there is no item version # conflict then commit succeeded
Scenario: no transaction reader, cache nodes with TTL(defaults to 30 seconds)
* Will do an L1/L2 caching where local memory is L1 & Redis is L2
  Will read Nodes and/or Items from L1/L2/C* & AWS S3 as appropriate
* Return error when fetching node or item that is missing
Scenario: no transaction
* Read: always read from Redis/C* & AWS S3 as appropriate
* Write: wrap the action in a transaction to protect the system from corruption
  - issue a begin transaction
  - do the mgmt action(add, update or delete)
  - commit the transaction
  - return pass or failure(error)

Transaction & B-Tree Stores
* There will be a global Transaction object which will track all managed items done across all B-Tree Stores
* A B-Tree instance may create its own Transaction if there is no global Transaction ongoing

Implementation Schedule
* V1 - B-tree in-memory with interfaces for easy plugin to a backend data storage, e.g. - S3 & Cassandra.
* V2 - Backend storage, e.g. - Cassandra for registry & S3 bucket for node blobs.
* V3 - Support for streaming persistence, e.g. - persisting a Very Large Object(VLobs) like a 2-200+GB movie.
* V4 - Local file system as backend storage.

Long Lived Transactions(TODO in far future)
* Store changes to transaction table (i.e. - transaction sandbox)
* During Commit:
*   - maps to destination table(s) the changes
*   - if same Node record is modified by another transaction.. implement a "undo" of any changes in the B-Tree 
*     then re-issue the "action" mapping.
*   - rollback any changes if retry is maxed out and/or timeout is reached
*   - if an item being managed was modified(different version) then rollback as well
*   - finalize commit if successfully mapped

Logical ID to Physical ID story (VirtualIdRepository)
A. Node ID handling
- Btree reader will always use Logical ID so it can read the "active" Node
- During a Transaction phase 1 commit:
	 - Updated Nodes will actually be "new" Nodes that are copies of the currently "active" Node.
	 - New Nodes will be persisted with (final) Logical ID to Physical ID map.
- During phase 2 commit:
	 - Updated Nodes' Physical ID will be made the current "active" Node in the Virual Registry.

B. Value ID handling
- Logical ID handling does not apply for Values stored on Node itself as there is no separate entry for it.
- Values that are stored in separate Value table (e.g. - slot_value) will be handled similar
to Node Update described above.

NOTE: Based on above story, Logical ID handling will be the default ID known to Btree. There is a
special override action, that is:
- Updated Nodes will "know" it is "new" and has Logical ID entry persisted for use during phase 2 commit.
During phase 2 commit, handler will use this Logical ID to make it the "active" Node.
- Other objects like Value stored in separate table, will be handled similar to updated Node.


Transaction feature detailed discussion:
Feature discussion:
  Transaction commit logic(in Transaction):
	NOTE: Any error in redis or Cassandra will return the error and should trigger a rollback. Writers will only
	work if redis and Cassandra are operational. Readers however, can still work despite redis failure(s).

	Reader transaction:
	- Check all explicitly fetched(i.e. - GetCurrentKey/GetCurrentValue invoked) & managed(add/update/remove) items
	  if they have the expected version number. If different, rollback.
	  Compare local vs redis/blobStore copy and see if different. Read from blobStore if not found in redis.
	  Commit to return error if there is at least an item with different version no. as compared to
	  local cache's copy.

	Writer transaction:
    1. Conflict Resolution:
	- Check all explicitly fetched(i.e. - GetCurrentKey/GetCurrentValue invoked) & managed(add/update/remove) items
	  if they have the expected version number. If different, rollback.
	  Compare local vs redis/blobStore copy and see if different. Read from blobStore if not found in redis.
	- Mark these items as locked in Redis.
	  Rollback if any failed to lock as alredy locked by another transaction. Or if Redis fetch failed(error).

	Applicable for writer transaction.
	2.1 Save the modified(added/updated/removed) Node(s) as inactive:
	NOTE: a transaction Commit can timeout and thus, rollback if it exceeds the maximum time(defaults to 30 mins).
	Phase 1(modified Node(s) merging):
	NOTE: Return error to trigger rollback for any operation below that fails.
	- Create a lookup table of added/updated/removed items together with their Nodes
	  Specify whether Node is updated, added or removed
	* Repeat until timeout, for updated Nodes:
	- Upsert each Node from the lookup to blobStore(Add only if blobStore is S3)
	- Log UUID in transaction rollback log categorized as updated Node
	- Compare each updated Node to Redis copy if identical(active UUID is same)
	  NOTE: added Node(s) don't need this logic.
	  For identical Node(s), update the "inactive UUID" with the Node's UUID(in redis).
	  Collect each Node that are different in Redis(as updated by other transaction(s))
	  Gather all the items of these Nodes(using the lookup table)
	  Break if there are no more items different.
	- Re-fetch the Nodes of these items, re-create the lookup table consisting only of these items & their re-fetched Nodes
	- Loop end.
	- Return error if loop timed out to trigger rollback.

	* For removed Node(s):
	- Log removed Node(s) UUIDs in transaction rollback log categorized as removed Nodes.
	- Add removed Node(s) UUIDs to the trash bin so they can get physically removed later.
	* For newly added Node(s):
	- Log added Node(s) UUID(s) to transaction rollback log categorized as added virtual IDs.
	- Add added Node(s) UUID(s) to virtual ID registry(cassandra then redis)
	- Add added Node(s) data to Redis

  2.2 Save all modified Stores
  - Update Cassandra of the Stores' updates, merging or adding the added count in each Store
    to what is in the Redis cache/Cassandra, if there is change.

	3. Mark inactive Node(s) as active (in both redis & Cassandra):
	NOTE: Return error to trigger rollback for any operation below that fails.
	- Mark all the updated Node(s)' virtual ID records as locked.
	  Detect if Node(s) in Redis had been modified, if yes, unlock them then return error to trigger rollback.
	- Update the virtual ID records to make inactive as active
	- Mark all the affected Node(s)' virtual ID records as unlocked
	- Mark all the items as unlocked in Redis
	- Delete the transaction logs for this transaction.

	4. Mark transaction session as committed(done).
	Transaction Cleanup:
	- Clear all local cache created in the transaction.
	- Mark transaction as completed(hasBegun=false).
	- Mark transaction as unusable, a begin action to the same instance will return error.
	- All B-Tree instances that are bound to the transaction will now be unbound, thus, any action
	  on them will not be bound to any transaction, thus, activate the on-the-fly transaction wrapping.

	5. Rollback
	- Read the transaction logs and delete all (temporary) data(in S3) created by this transaction or
	  mark "deleted=true" for the Cassandra records so they can be scheduled for deletion at a later, non-busy time.
	  Mark as appropriate according to different categories.
	- Call Transaction Cleanup to finalize rollback.
